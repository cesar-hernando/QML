{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78cf3ef",
   "metadata": {},
   "source": [
    "# quantum_machine_learning.myQML.QCBM\n",
    "\n",
    "**class quantum_machine_learning.myQML.QCBM(n_qubits, basis, n_blocks, n_shots, device, sigma_list_kernel, ansatz_mode=0, execution_mode=0, dimension=None)**    \n",
    "\n",
    "QCBM is a generative model that encodes the probability distribution of classical data as a variational quantum circuit, and it is based on Born's postulate of Quantum Mechanics, which states that the probabiliy of obtaining the bitstring x as a result of measuring the quantum state $|\\psi_\\theta \\rangle$ is $|\\langle x | \\psi_\\theta \\rangle|^2$. In contrast to other methods such as Restricted Boltzmann machines, QCBM samples efficiently, as it just requires executing the quantum circuit. \n",
    "\n",
    "Regarding the training process, the variatioanl circuit is initialized with random parameters, and for each iteration it produces a specified number of samples and a loss function is evaluated, which measures the distance between the target distribution and the model distribution. The QCBM method employs the squared mean discrepancy loss with a Radial Basis Function (RBF) kernel. Similarly to supervised QNNs, the gradient f the loss function with respect to the variational parameters can be evaluated exactly via the Parameter Shift Rule. Thus, we can use gradient-based optimizers such as Adam or L-BFGS-B.\n",
    "\n",
    "After the optimal parameters are found and training is finished, we will generate samples from the circuit and analyse their validity. Apart from the precision metric, which measure the rate of generating valid patterns, there are other metrics that measure generalzation, which refers to not only considering the validity criterium but also whether the generated sample was seen in training. However, since our dataset is very small, it does not make sense to study its generalizability.\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **n_qubits** (int): Number of qubits employed for the parametrized quantum circuit. $2^{n_\\text{qubits}}$ must be equal or greater than the number of possible states in the dataset.\n",
    "- **basis** (numpy.ndarray): Array of shape $(2^{n_{\\text{qubits}}}, \\sqrt{n_{\\text{qubits}}}, \\sqrt{n_{\\text{qubits}}})$\n",
    ", assuming the dataset is made of squared images of N x N = n_qubits pixels.\n",
    "- **n_blocks** (int): Number of blocks in the variational quantum layer, where each of the blocks contains rotational gates and CNOTs (or other entangling two-qubit gates).\n",
    "- **n_shots** (int): Number of executions of the corresponding quantum circuit to estimate a probability or the expectation value of an observable. If n_shots = None, the estimation of the quantum simulator has no shot noise.\n",
    "- **optimizer_name** (str): Label of the optimizer used for the training of the classical neural network. Only 'Adam' optimizer is implemented currently.\n",
    "- **device** (str): Can be either 'myQLM' or 'Qaptiva', depending if you want to use the Qaptiva plugin instead of your own laptop for the quantum circuit simulations.\n",
    "- **sigma_list_kernel** (list): List of the standard deviations of the gaussians in the multi radial basis function (RBF) kernel, used for the two sample test loss.\n",
    "- **ansatz_mode** (int): Given that there are many possible ansatz choices for parametrized quantum circuits, this variables selects the one chosen. Currently, only one ansatz is implemented, accessed using ansatz_mode = 0.\n",
    "- **execution_mode** (int): If equals to 0, the quantum circuit is executed with no shot noise in myQLM and then samples are obtained using numpy.random; and if equals to 1, shot noise in myQLM is implemented. \n",
    "- **dimension** : Shape of the images. The products of the dimensions must be equal to the number of qubits required for the parametrized quantum circuit.\n",
    "\n",
    "\n",
    "**ansatz(params)**\n",
    "\n",
    "This method defines the parametrized quantum circuit with given rotational gates angles/parameters, measuring in the computational basis n_shots times, obtaining n_shots samples.\n",
    "\n",
    "**Parameters:**\n",
    "- **params** (numpy.ndarray): Array of n_params = 3 x n_qubits x n_blocks elements with the angles of the rotational gates of the quantum circuit. These parameters are varied to minimize the loss and learn the target probability distribution.\n",
    "\n",
    "**Returns**: samples (numpy.ndarray) - n_shots samples obtained by the quantum measurement in the computational basis, and circuit (qat.core.circuit.Circuit) - the compiled quantum circuit in myQLM.\n",
    "\n",
    "\n",
    "**estimate_probs(params)**\n",
    "\n",
    "This method calls the ansatz method, and with the returned samples, estimates the corresponding probability distribution. \n",
    "\n",
    "**Parameters:**\n",
    "- **params** (numpy.ndarray): Array containing the angles of all rotational gates of the parametrized quantumcircuit. The number of elements is 3 x n_qubits x n_blocks using the Hardware Efficient Ansatz (HEA).\n",
    "\n",
    "**Returns:** The estimated probability distribution, which approximates the target distribution.\n",
    "\n",
    "**Return type:**  numpy.ndarray of $2^{n_\\text{qubits}}$ elements.\n",
    "\n",
    "\n",
    "**multi_rbf_kernel(x, y, sigma_list)**\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **x** (numpy.ndarray): \n",
    "- **y** (numpy.ndarray): \n",
    "- **sigma_list** : \n",
    "\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "**Return type:** \n",
    "\n",
    "\n",
    "**classical_model()**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "\n",
    "\n",
    "**kernel_expectation(px, py, kernel_matrix)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **px** (numpy.ndarray): \n",
    "- **py** (numy.ndarray):\n",
    "- **kernel_matrix** (numpy.ndarray):\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "\n",
    "**loss_function(params, target_probs, kernel_matrix)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **params** (numpy.ndarray):\n",
    "- **target_probs** (numpy.ndarray):\n",
    "- **kernel_matrix** (numpy.ndarray)\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "\n",
    "\n",
    "**gradient(theta, kernel_matrix, target_probs)**\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **theta** (numpy.ndarray):\n",
    "- **kernel_matrix** (numpy.ndarray):\n",
    "- **target_probs** (numpy.ndarray):\n",
    "\n",
    "**Returns:**  \n",
    "\n",
    "\n",
    "\n",
    "**fit(method=\"L-BFGS-B\", learning_rate=0.1, tol=1e-5, max_iter=20, g_tol=1e-10, f_tol=0, x_tr=None, target_probs=None)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **method** (str):\n",
    "- **learning_rate** (float):\n",
    "- **tol** (float):\n",
    "- **max_iter** (int):\n",
    "- **g_tol** (float):\n",
    "- **f_tol** (float):\n",
    "- **x_tr** (numpy.ndarray):\n",
    "- **target_probs** (numpy.ndarray):\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "\n",
    "\n",
    "**plot_loss(tracking_cost)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **tracking_cost** (numpy.ndarray):\n",
    "\n",
    "**Returns:**\n",
    "\n",
    "**plot_generated_distribution(samples)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **samples** (numpy.ndarray):\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "**generate_samples(n_samples)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **n_samples** (int):\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "**plot_generated_samples(samples_matrix)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **samples_matrix** (numpy.ndarray):\n",
    "\n",
    "**Returns:** \n",
    "\n",
    "**calculate_metrics(samples_matrix, x_tr, validity_fn, n_sols, cost_fn)**\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **samples_matrix** (numpy.ndarray):\n",
    "- **x_tr** (numpy.ndarray):\n",
    "- **validity_fn** (function):\n",
    "- **n_sols** (int):\n",
    "- **cost_fn** (function):\n",
    "\n",
    "**Returns:** \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
