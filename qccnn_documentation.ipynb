{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87de98c",
   "metadata": {},
   "source": [
    "# quantum_machine_learning.myQML.QCCNN\n",
    "\n",
    "**class quantum_machine_learning.myQML.QCCNN(n_qubits, device, n_blocks, n_shots, optimizer_name, loss, learning_rate = 0.01, opt_model_path=None, np_arrays_path=None)**    \n",
    "\n",
    "Class to solve an Supervised Machine Learning image multi-class classification problem using a Quantum-Classical Convolutional Neural Network. It defines a quantum convolutional layer and then a classical convolutional neural network. First, using random quantum variational angles, it processes the images and trains the classical network to find the optimal classical weights, and then, with these fixed weights, it trains the quantum layer. This algorithm is inspired by the paper *Quanvolutional Neural Networks: Powering image Recognition with Quantum Circuits* by Henderson et al. However, in the paper the angles of the quantum convolutional layer are fixed, while here we optimize them too. \n",
    "\n",
    "**Parameters:**\n",
    "- **n_qubits** (int): Number of qubits used for the quantum circuit, which depends of the size of the quantum kernel used to process the image.\n",
    "- **device** (str): Indicates whether the quantum circuits are executed locally (myQLM) or sent to a Qaptiva emulator as batches.\n",
    "- **n_blocks** (int): Number of blocks in the variational quantum layer, where each of the blocks contains rotational gates and CNOTs (or other entangling two-qubit gates).\n",
    "- **n_shots** (int): Number of executions of the corresponding quantum circuit to estimate a probability or the expectation value of an observable. If n_shots = None, the estimation of the quantum simulator has no shot noise.\n",
    "- **optimizer_name** (str): Label of the optimizer used for the training of the classical neural network. Only 'Adam' optimizer is implemented currently.\n",
    "- **loss** (str): Label of the loss function used for the training of the classical neural network, e.g. 'sparse_categorical_crossentropy'. Any loss function label already implemented in tensorflow keras can be used.\n",
    "- **learning_rate** (str): Size of the step in the Adam optimizer. Not needed if a different optimizer is used.\n",
    "- **opt_model_path** (str): Path where the optimal classical convolutional neural network is going to be saved.\n",
    "- **np_arrays_path** (str): Path where the images after the quantum processing are saved, as well as the quantum random angles used for that processing.\n",
    "\n",
    "\n",
    "**quantum_conv_kernel_circuit(x)**\n",
    "\n",
    "This method implements a quantum convolutional kernel circuit for a custom QCCNN. It first applies an angle encoding feature map to map the input data (portion of the image) to a quantum state, and then applies series of rotation gates with random angles and CNOT gates to the qubits.\n",
    "\n",
    "**Parameters:**\n",
    "- **x** (numpy.ndarray): Input data vector of length n_qubits that is used as input angles of the rotation gates applied to each qubit in the feature map. \n",
    "\n",
    "**Returns**: An array of n_qubits elements with the Z expectation value of each of the qubits.\n",
    "\n",
    "**Return type**:  numpy.ndarray\n",
    "\n",
    "\n",
    "**quantum_conv_layer(image)**\n",
    "\n",
    "This method slides the quantum kernel circuit through the whole images and returns the corresponding output image.\n",
    "\n",
    "\n",
    "**Parameters:**\n",
    "- **image** (numpy.ndarray): Rank 2 or 3 tensor with the pixel values of the image (with possibly more than one channel). \n",
    "\n",
    "**Returns:** The resulting image or tensor of usually rank 3.\n",
    "\n",
    "**Return type:** numpy.ndarray \n",
    "\n",
    "\n",
    "**quantum_conv_preprocessing(train_images, test_images=None, save=True, params=None)**\n",
    "\n",
    "This method calls quantum_conv_layer for all the images in the training and test sets, and stack the resulting tensor forming a rank 4 tensor for each set.\n",
    "\n",
    "**Parameters:**\n",
    "- **train_images** (numpy.ndarray): Images (with possibly multiple channels) in the training set used to optimize the network.\n",
    "- **test_images** (numpy.ndarray): Images (with possibly multiple channels) in the test set used to assess the performance of the network.\n",
    "- **save** (bool): Determines whether the train and test output quantum images are saved.\n",
    "- **params** (numpy.ndarray): Array of the random angles of the variational ansatz of the quantum convolutional layer. If None, a new array of andom angle is created.\n",
    "\n",
    "**Returns:** The output tensors resulting from the quantum preprocessing of the training and test sets, i.e., the quantum_train_images and quantum_test_images. It also returns the random angles employed.\n",
    "\n",
    "**Return type:** quantum_train_images - numpy.ndarray (4D), quantum_test_images - numpy.ndarray (4D), params - numpy.ndarray (1D).\n",
    "\n",
    "\n",
    "**classical_model()**\n",
    "\n",
    "Defines a classical CNN model (using tensorflow keras) with custom hidden layers with the desired filters, kernel size and ativation function, as well as the output layer with the dsired number of classes and activation function. Additionally, it specifies the optimizer, loss function and metrics (such as the accuracy).\n",
    "\n",
    "**Returns:** The compiled tensorflow keras model.\n",
    "\n",
    "\n",
    "\n",
    "**train(preprocessing, train_images, train_labels, validation_images, validation_labels, batch_size, n_epochs, early_stop_crit=False, patience=None, min_delta=None)**\n",
    "\n",
    "This method trains the QCCNN model using the quantum convolutional preprocessing images as input, optimizing the classical CNN to minimize the training loss.\n",
    "\n",
    "**Parameters:**\n",
    "- **preprocessing** (bool): Indicates whether quantum preproccsing is required, in case the input images have arleady been processed with the quantum layer.\n",
    "- **train_images** (numpy.ndarray): Images (with possibly multiple channels) in the training set used to optimize the network.\n",
    "- **train_labels** (numpy.ndarray): Array containing the labels of each of the training images.\n",
    "- **validation_images** (numpy.ndarray): Images (with possibly multiple channels) not used for training but for monitoring the performance of the training.\n",
    "- **validation_labels** (numpy.ndarray): Labels of the validation images.\n",
    "- **batch_size** (int): The number of training images in a batch used to calculate the average loss function and its gradient to update the network weights and biases, typically used in stochastic gradient descent based methods.\n",
    "- **n_epochs** (int): Number of times the whole training set is utilized to update the network weights and biases. In each of the epochs, different batches are formed, and used to evaluate the loss function and gradient to optimize the neural network\n",
    "- **early_stop_crit** (bool): Determines whether an early stop criterium based on validation images is used to prevent overfitting\n",
    "- **patience** (int): Number of epochs to continue training after the last time the monitored performance metric improved. If the metric does not improve within this number of epochs, training stops early.\n",
    "- **min_delta** (float): Minimum change in the monitored metric (validation accuracy) that classifies as mprovement. Changes smaller than min_delta are considered insignificant and do not reset the patience counter.\n",
    "\n",
    "**Returns:** The training history, including the training and validation accuracy and loss at each epoch.\n",
    "\n",
    "\n",
    "**plot_quantum_images(train_images, quantum_train_images, n_samples)**\n",
    "\n",
    "Plot n_samples examples of the output images resulting from the quantum convolutional layer preprocessing.\n",
    "\n",
    "**Parameters:**\n",
    "- **train_images** (numpy.ndarray): Images (with possibly multiple channels) in the training set used to optimize the network. This multidimensional array is a rank 3 tensor if there is only one channel and a rank 4 tensor if there are more than one (rgb colors).\n",
    "- **quantum_train_images** (numpy.ndarray): Images after applying the quantum convolutional preprocessing. Each quantum output image is a rank 3 tensor, so the set of all the images is a rank 4 tensor.\n",
    "- **n_samples**: Number of example images plotted.\n",
    "\n",
    "**Returns:** This method does not return any variable, but shows the figure in the notebook/terminal and saves it.\n",
    "\n",
    "\n",
    "\n",
    "**plot_loss(c_history=None, fig_path=None, fig_name='qccnn_loss.png')**\n",
    "\n",
    "Plots two figures: one for the evolution of the training and validation accuracy of the model with and without the quantum convolutional layer, and the same figure but for the loss.\n",
    "\n",
    "**Parameters:**\n",
    "- **c_history** (keras.callbacks.History): Training and validation accuracy, and training and validation loss of the netwrok in each epochs.\n",
    "- **fig_path** (str): Path where the figure is saved.\n",
    "- **fig_name** (str): Name of the saved image.\n",
    "\n",
    "**Returns:**  This method does not return any variable, but shows the figure in the notebook/terminal and saves it.\n",
    "\n",
    "\n",
    "\n",
    "**optimize_quantum_params(train_images, train_labels, method='cobyla', max_iter=10, n_init=5, n_iters=20)**\n",
    "\n",
    "Fixing the optimal weights and biases of the classical CNN, we vary the angles of the rotational gates in the quantum layer to minimize the training loss, using different training data. We implement wo different gradient-free optimization methods: Cobyla and Bayesian Optimization. In the future, parameter shift rule or autodifferentiation could be implemented.\n",
    "\n",
    "**Parameters:**\n",
    "- **train_images** (numpy.ndarray): Images (with possibly multiple channels) in the training set used to optimize the network. This multidimensional array is a rank 3 tensor if there is only one channel and a rank 4 tensor if there are more than one (rgb colors).\n",
    "- **train_labels** (numpy.ndarray): Array containing the labels of each of the training images.\n",
    "- **method** (str): Can be 'cobyla' or 'bayesian_optimization'\n",
    "- **max_iter** (int): Maximum number of iterations (for cobyla)\n",
    "- **n_init** (int): Initial number of evalutations at random parameters within the bounds.\n",
    "- **n_iters** (int): Number of iterations of bayesian optimization.\n",
    "\n",
    "**Returns:** The history of the optimization (training loss at each epoch), an array wth the training accuracies, and an array with the training losses.\n",
    "\n",
    "\n",
    "\n",
    "**predict(preprocessing, test_images, test_labels)**\n",
    "\n",
    "Evaluates the performance of the quantum enhanced convolutional network on the test set.\n",
    "\n",
    "**Parameters:**\n",
    "- **preprocessing** (bool): Indicates whether it is necessary to do the quantum preprocessing on the test images. If an optimization of the angles in the quantum layer has been performed, then, preprocessing with those optimized angles is required.\n",
    "- **test_images** (numpy.ndarray): Images (with possibly multiple channels) not used for training but for assessing the performance of the network at classifying the images.\n",
    "- **test_labels** (numpy.ndarray): Labels of the test images.\n",
    "\n",
    "**Returns:** The test loss and test accuracy (both float variables).\n",
    "\n",
    "\n",
    "\n",
    "**plot_q_train_loss(train_accuracies, train_losses, fig_path=None, fig_name='qccnn_quantum_loss.png')**\n",
    "\n",
    "Plots the training accuracy during the optimization of the angles in the quantum convolutional layer.\n",
    "\n",
    "**Parameters:**\n",
    "- **train_accuracies** (numpy.ndarray): Array with the training accuracy in each optimization step. \n",
    "- **train_losses** (numpy.narray): Array with the train loss in each optimization step.\n",
    "- **fig_path**: Path where this figure is saved.\n",
    "- **fig_name**: Name of the figure saved as an image.\n",
    "\n",
    "**Returns:** This method does not return any variable, but shows the figure in the notebook/terminal and saves it.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
